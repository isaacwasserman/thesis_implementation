{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install igraph\n",
    "!pip install scikit-image==0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNEMS.GNEMS import GNEMS_segment\n",
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import label2rgb\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(hyperparams, label=None):\n",
    "    if label is None:\n",
    "        method_name = f\"GNEMS_alternate_{time.time()}\"\n",
    "    else:\n",
    "        method_name = f\"GNEMS_{label}\"\n",
    "\n",
    "    assert not os.path.exists(f\"results/{method_name}\"), \"Directory already exists!\"\n",
    "\n",
    "    !mkdir results/{method_name}\n",
    "    !mkdir results/{method_name}/noise\n",
    "    !mkdir results/{method_name}/noise/0.5\n",
    "    !mkdir results/{method_name}/noise/1.0\n",
    "    !mkdir results/{method_name}/noise/2.0\n",
    "    !mkdir results/{method_name}/noise/4.0\n",
    "    !mkdir results/{method_name}/noise/8.0\n",
    "    !mkdir results/{method_name}/clouds\n",
    "    !mkdir results/{method_name}/texture\n",
    "\n",
    "    with open(f\"results/{method_name}/hyperparams.json\", \"w\") as f:\n",
    "        json.dump(hyperparams, f)\n",
    "\n",
    "    def segment_and_save(path, id, bar=None):\n",
    "        im = np.array(Image.open(path).convert(\"L\"))\n",
    "        d = hyperparams[\"d\"]\n",
    "        iterations = hyperparams[\"iterations\"]\n",
    "        prediction_stride = hyperparams[\"prediction_stride\"]\n",
    "        lambda_ = hyperparams[\"lambda_\"]\n",
    "        slic_segments = hyperparams[\"slic_segments\"]\n",
    "        sigma = hyperparams[\"sigma\"]\n",
    "        seg = GNEMS_segment(im, d=d, lambda_=lambda_, iterations=iterations, prediction_stride=prediction_stride, slic_segments=slic_segments, sigma=sigma, show_progress=False)\n",
    "        category = path.split(\"/\")[1]\n",
    "        Image.fromarray(seg).convert(\"L\").save(f\"results/{method_name}/{category}/{id}.png\")\n",
    "        bar.update(1)\n",
    "\n",
    "    print(\"Segmenting clouds dataset...\")\n",
    "    with open(\"datasets/clouds/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/clouds/images/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            while len(threading.enumerate()) >= 32:\n",
    "                time.sleep(1)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    with open(\"datasets/noise/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    print(\"Segmenting noise dataset...\")\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/noise/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            while len(threading.enumerate()) >= 32:\n",
    "                time.sleep(1)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    print(\"Segmenting texture dataset...\")\n",
    "    with open(\"datasets/texture/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/texture/images/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            while len(threading.enumerate()) >= 32:\n",
    "                time.sleep(1)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise/0.5’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise/1.0’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise/2.0’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise/4.0’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/noise/8.0’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/clouds’: File exists\n",
      "mkdir: cannot create directory ‘results/GNEMS_larger_patches/texture’: File exists\n",
      "Segmenting clouds dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:52<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting noise dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1280/1280 [04:21<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting texture dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [02:39<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"d\": 8,\n",
    "    \"iterations\": 50,\n",
    "    \"prediction_stride\": 8,\n",
    "    \"lambda_\": 0.3,\n",
    "    \"n_filters\": 16,\n",
    "    \"slic_segments\": 100,\n",
    "    \"sigma\": 3\n",
    "}\n",
    "run_tests(hyperparams, label=\"larger_patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
