{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install igraph\n",
    "!pip install scikit-image==0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaac/miniforge3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GNEMS.GNEMS import GNEMS_segment\n",
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import label2rgb\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(hyperparams, label=None, max_threads=8):\n",
    "    if label is None:\n",
    "        method_name = f\"GNEMS_alternate_{time.time()}\"\n",
    "    else:\n",
    "        method_name = f\"GNEMS_{label}\"\n",
    "\n",
    "    assert not os.path.exists(f\"results/{method_name}\"), \"Directory already exists!\"\n",
    "\n",
    "    !mkdir results/{method_name}\n",
    "    !mkdir results/{method_name}/noise\n",
    "    !mkdir results/{method_name}/noise/0.5\n",
    "    !mkdir results/{method_name}/noise/1.0\n",
    "    !mkdir results/{method_name}/noise/2.0\n",
    "    !mkdir results/{method_name}/noise/4.0\n",
    "    !mkdir results/{method_name}/noise/8.0\n",
    "    !mkdir results/{method_name}/clouds\n",
    "    !mkdir results/{method_name}/texture\n",
    "\n",
    "    with open(f\"results/{method_name}/hyperparams.json\", \"w\") as f:\n",
    "        json.dump(hyperparams, f)\n",
    "\n",
    "    def segment_and_save(path, id, bar=None):\n",
    "        im = np.array(Image.open(path).convert(\"L\"))\n",
    "        d = hyperparams[\"d\"]\n",
    "        iterations = hyperparams[\"iterations\"]\n",
    "        prediction_stride = hyperparams[\"prediction_stride\"]\n",
    "        lambda_ = hyperparams[\"lambda_\"]\n",
    "        slic_segments = hyperparams[\"slic_segments\"]\n",
    "        sigma = hyperparams[\"sigma\"]\n",
    "        seg = GNEMS_segment(im, d=d, lambda_=lambda_, iterations=iterations, prediction_stride=prediction_stride, slic_segments=slic_segments, sigma=sigma, show_progress=False)\n",
    "        category = path.split(\"/\")[1]\n",
    "        Image.fromarray(seg).convert(\"L\").save(f\"results/{method_name}/{category}/{id}.png\")\n",
    "        bar.update(1)\n",
    "\n",
    "    print(\"Segmenting clouds dataset...\")\n",
    "    with open(\"datasets/clouds/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/clouds/images/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "            while len(threading.enumerate()) >= max_threads:\n",
    "                time.sleep(1)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    with open(\"datasets/noise/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    print(\"Segmenting noise dataset...\")\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/noise/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "            while len(threading.enumerate()) >= max_threads:\n",
    "                time.sleep(1)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    print(\"Segmenting texture dataset...\")\n",
    "    with open(\"datasets/texture/test_ids.txt\", \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    threads = []\n",
    "    with tqdm(total = len(test_ids)) as pbar:\n",
    "        for id in test_ids:\n",
    "            path = f\"datasets/texture/images/{id}.png\"\n",
    "            t = threading.Thread(target=segment_and_save, args=(path,id,pbar))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "            while len(threading.enumerate()) >= max_threads:\n",
    "                time.sleep(1)\n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting clouds dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/256 [00:47<3:20:40, 47.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m hyperparams \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m16\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m run_tests(hyperparams, label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlower_stride\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_threads\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m, in \u001b[0;36mrun_tests\u001b[0;34m(hyperparams, label, max_threads)\u001b[0m\n\u001b[1;32m     45\u001b[0m     threads\u001b[39m.\u001b[39mappend(t)\n\u001b[1;32m     46\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(threading\u001b[39m.\u001b[39menumerate()) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_threads:\n\u001b[0;32m---> 47\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m threads:\n\u001b[1;32m     49\u001b[0m     t\u001b[39m.\u001b[39mjoin()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"d\": 16,\n",
    "    \"iterations\": 50,\n",
    "    \"prediction_stride\": 4,\n",
    "    \"lambda_\": 0.3,\n",
    "    \"n_filters\": 16,\n",
    "    \"slic_segments\": 100,\n",
    "    \"sigma\": 3\n",
    "}\n",
    "run_tests(hyperparams, label=\"lower_stride\", max_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
