{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaac/miniforge3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33misaacwasserman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pprint\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.util as util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import igraph as ig\n",
    "from igraph import Graph\n",
    "import sklearn.metrics as metrics\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import skimage.filters\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage import data, segmentation, color\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext line_profiler\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def generate_square(size=(224, 224), fore_back_ratio=0.5, noise=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    square_width = int(np.sqrt(fore_back_ratio * size[0] * size[1]))\n",
    "    square_position_x = np.random.randint(0, size[0] - square_width)\n",
    "    square_position_y = np.random.randint(0, size[1] - square_width)\n",
    "    image = np.ones(size)\n",
    "    image[square_position_x:square_position_x+square_width, square_position_y:square_position_y+square_width] = 0\n",
    "    return image\n",
    "\n",
    "def add_noise(image, amount=0.5, seed=None):\n",
    "    image = util.random_noise(image, mode='gaussian', seed=seed, clip=False, var=amount)\n",
    "    image = image / np.max(image)\n",
    "    return image\n",
    "\n",
    "def generate_image(size=(224, 224), fore_back_ratio=0.5, noise=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    image = generate_square(size, fore_back_ratio, noise, seed)\n",
    "    pixelwise_labels = image.copy()\n",
    "    image = add_noise(image, amount=noise, seed=seed)\n",
    "    return image, pixelwise_labels\n",
    "\n",
    "def tile(image, pixelwise_labels=None, method='grid', d=10):\n",
    "    if method == 'grid':\n",
    "        if image.shape[0] % d != 0 or image.shape[1] % d != 0:\n",
    "            raise ValueError('image shape must be divisible by d')\n",
    "        else:\n",
    "            tile_width = (image.shape[0] // d)\n",
    "            tile_height = (image.shape[1] // d)\n",
    "            image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "            if len(image_tensor.shape) < 3:\n",
    "                image_tensor = image_tensor.unsqueeze(2)\n",
    "            tiles = image_tensor.unfold(0, tile_width, tile_height).unfold(1, tile_width, tile_height)\n",
    "            tiles = tiles.permute(0, 1, 3, 4, 2)\n",
    "            tiles = tiles.reshape(tiles.shape[0] * tiles.shape[1], tile_width, tile_height, tiles.shape[4])\n",
    "\n",
    "            if pixelwise_labels is not None:\n",
    "                pixelwise_labels_tensor = torch.tensor(pixelwise_labels)\n",
    "                if len(pixelwise_labels_tensor.shape) < 3:\n",
    "                    image_tensor = image_tensor.unsqueeze(2)\n",
    "                pixelwise_labels_tiles = pixelwise_labels_tensor.unfold(0, tile_width, tile_height).unfold(1, tile_width, tile_height)\n",
    "                pixelwise_labels_tiles = pixelwise_labels_tiles.reshape(pixelwise_labels_tiles.shape[0] * pixelwise_labels_tiles.shape[1], tile_width * tile_height)\n",
    "                tilewise_labels = pixelwise_labels_tiles.mean(axis=1).round()\n",
    "                return tiles, tilewise_labels\n",
    "            else:\n",
    "                return tiles\n",
    "    else:\n",
    "        raise ValueError('method not implemented')\n",
    "    \n",
    "\n",
    "def arbitrary_labels(n, proportion=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.random.manual_seed(seed)\n",
    "    randoms = torch.rand(n)\n",
    "    labels = torch.zeros(n)\n",
    "    labels[randoms > proportion] = 1\n",
    "    return labels\n",
    "\n",
    "def generate_tiles(size=(224, 224), fore_back_ratio=0.5, noise=0.5, d=8, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    image, pixelwise_labels = generate_image(size, fore_back_ratio, noise, seed)\n",
    "    tiles, tilewise_labels = tile(image, pixelwise_labels, d=d)\n",
    "    return tiles, tilewise_labels, arbitrary_labels(tilewise_labels.shape[0], seed=seed)\n",
    "\n",
    "def visualize_tiles(tiles, tilewise_labels=None, show_labels=True):\n",
    "    d = int(np.sqrt(tiles.shape[0]))\n",
    "    fig, axs = plt.subplots(d,d, figsize=(d//2,d//2))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            axs[i, j].imshow(tiles[i * d + j], cmap='gray', vmin=0, vmax=1)\n",
    "            if show_labels and tilewise_labels is not None:\n",
    "                axs[i, j].text(2, 2, f'{tilewise_labels[i * d + j]:.2f}', color='white', fontsize=6, bbox=dict(fill=True, facecolor='purple', linewidth=0), verticalalignment='top', horizontalalignment='left')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def graph_cut(d, probabilities, lambda_):\n",
    "    g = Graph.Lattice(dim=[d, d], circular=False)\n",
    "    g.add_vertices(2)\n",
    "    weights = np.zeros(g.ecount() + (2*d*d))\n",
    "    s = d*d\n",
    "    t = s + 1\n",
    "    st_edges = np.array([(i, s) for i in range(d*d)] + [(i, t) for i in range(d*d)])\n",
    "    g.add_edges(st_edges)\n",
    "    weights[:-2*d*d] = lambda_\n",
    "    scaled_probabilities = (probabilities - probabilities.min()) / (probabilities.max() - probabilities.min())\n",
    "    weights[-2*d*d:-1*d*d] = scaled_probabilities\n",
    "    weights[-1*d*d:] = 1 - scaled_probabilities\n",
    "    g.es['weight'] = weights\n",
    "\n",
    "    colors = np.concatenate((np.zeros(d*d), np.array([1,2])))\n",
    "    g.vs[\"color\"] = [\"gray\" if c == 0 else (\"black\" if c == 1 else \"white\") for c in colors]\n",
    "\n",
    "    # assignments = np.array(g.maxflow(s, t, \"weight\").membership[:-2])\n",
    "\n",
    "    mc = g.st_mincut(s, t, \"weight\")\n",
    "    bg = mc.partition[0]\n",
    "    bg.remove(s)\n",
    "    assignments = np.zeros(d*d)\n",
    "    assignments[bg] = 1\n",
    "    return assignments, g\n",
    "\n",
    "def visualize_graph(g, d, labels=None):\n",
    "    if labels is None:\n",
    "        colors = np.concatenate((np.zeros(d*d), np.array([2,3])))\n",
    "        g.vs[\"color\"] = [\"gray\" if c == 0 else (\"black\" if c == 2 else \"white\") for c in colors]\n",
    "    else:\n",
    "        colors = np.concatenate((labels.astype(int), np.array([1,0])))\n",
    "        g.vs[\"color\"] = [\"black\" if c == 0 else \"white\" for c in colors]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    layout = np.zeros((d*d + 2, 2))\n",
    "    for i in range(d*d + 2):\n",
    "        if i < d*d:\n",
    "            layout[i, 0] = (i % d)\n",
    "            layout[i, 1] = -1 * (i // d)\n",
    "        elif i == d*d:\n",
    "            layout[i, 1] = 2\n",
    "            layout[i, 0] = (d - 1) / 2\n",
    "        elif i == d*d + 1:\n",
    "            layout[i, 1] = -1 * (d + 1)\n",
    "            layout[i, 0] = (d - 1) / 2\n",
    "\n",
    "    n_edges = g.ecount()\n",
    "    n_lattice_edges = n_edges - 2*d*d\n",
    "            \n",
    "    ig.plot(g, target=ax, edge_width=g.es[\"weight\"], layout=layout)\n",
    "    plt.show()\n",
    "\n",
    "def auto_threshold(probabilities):\n",
    "    t = skimage.filters.threshold_otsu(probabilities)\n",
    "    return t\n",
    "\n",
    "def evaluate(pixelwise_probabilities, pixelwise_labels, allow_inverse=True, plot=True):\n",
    "    pixelwise_predictions = pixelwise_probabilities\n",
    "    pixelwise_predictions = pixelwise_predictions.astype(int).reshape(-1)\n",
    "    pixelwise_labels = pixelwise_labels.astype(int).reshape(-1)\n",
    "    accuracy = accuracy_score(pixelwise_labels, pixelwise_predictions)\n",
    "    if allow_inverse and accuracy < 0.5:\n",
    "        pixelwise_predictions = 1 - pixelwise_predictions\n",
    "        accuracy = accuracy_score(pixelwise_labels, pixelwise_predictions)\n",
    "    report = classification_report(pixelwise_labels, pixelwise_predictions, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(pixelwise_labels, pixelwise_predictions)\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "        sns.heatmap(conf_matrix, ax=axs[0], annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "        axs[0].set_title('Confusion Matrix')\n",
    "        sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, ax=axs[1], annot=True)\n",
    "        axs[1].set_title('Classification Report')\n",
    "        illustration = pixelwise_labels.reshape(pixelwise_probabilities.shape[0], pixelwise_probabilities.shape[1]) != pixelwise_predictions.reshape(pixelwise_probabilities.shape[0], pixelwise_probabilities.shape[1])\n",
    "        axs[2].imshow(illustration)\n",
    "        axs[2].set_title('Incorrect Predictions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        return accuracy, report, conf_matrix\n",
    "\n",
    "class TileDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, image_size=(32,32), n_filters=16, n_channels=1, dropout=0.2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, n_filters, 3, padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(n_filters)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters, 3, padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(n_filters)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.conv3 = nn.Conv2d(n_filters, 1, 3, padding=1)\n",
    "        self.BN3 = nn.BatchNorm2d(1)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(image_size[0] * image_size[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.BN1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.BN2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.BN3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphicallyGuidedEMSegmentor:\n",
    "    def __init__(self, d=16, n_filters=16, dropout=0.2, lambda_=0.3, size=(512, 512), lr=0.001, iterations=100, subset_size=0.5, prediction_stride=1, seed=0):\n",
    "        self.d = d\n",
    "        self.n_filters = n_filters\n",
    "        self.dropout = dropout\n",
    "        self.lambda_ = lambda_\n",
    "        self.size = size\n",
    "        self.tile_size = (size[0] // d, size[1] // d)\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.subset_size = subset_size\n",
    "        self.prediction_stride = prediction_stride\n",
    "        self.seed = seed\n",
    "        self.net = None\n",
    "        self.losses = []\n",
    "        self.intermediate_partitions = []\n",
    "        self.intermediate_probabilities = []\n",
    "        self.intermediate_graphs = []\n",
    "\n",
    "    def fit(self, image):\n",
    "        self.losses = []\n",
    "        self.intermediate_partitions = []\n",
    "        self.intermediate_probabilities = []\n",
    "        self.intermediate_graphs = []\n",
    "        self.image = image\n",
    "        \n",
    "        X = tile(image, d=self.d).type(torch.float32).to(device).permute(0, 3, 1, 2)\n",
    "        y_initial = arbitrary_labels(self.d**2, seed=self.seed).type(torch.float32).to(device).unsqueeze(1)\n",
    "        torch.manual_seed(self.seed)\n",
    "        self.net = CNN(image_size=self.tile_size, n_filters=self.n_filters, n_channels=X.shape[1], dropout=self.dropout).to(device)\n",
    "        \n",
    "        # train CNN\n",
    "        y_intermediate = y_initial.clone().detach()\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            # extract subset of data\n",
    "            shuffled_idx = torch.randperm(X.shape[0])\n",
    "            X_shuffled = X[shuffled_idx]\n",
    "            y_intermediate_shuffled = y_intermediate[shuffled_idx]\n",
    "            X_subset = X_shuffled[:int(self.subset_size * X.shape[0])]\n",
    "            y_intermediate_subset = y_intermediate_shuffled[:int(self.subset_size * X.shape[0])]\n",
    "\n",
    "            inputs = X_subset\n",
    "            labels = y_intermediate_subset\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update y_intermediate\n",
    "            probabilities = self.net(X).detach().squeeze(1).cpu().numpy()\n",
    "            partition, g = graph_cut(self.d, probabilities, self.lambda_)\n",
    "            y_intermediate = torch.Tensor(partition).type(torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "            # save intermediate results\n",
    "            self.losses.append(loss.item() / X.shape[0])\n",
    "            self.intermediate_partitions.append(partition)\n",
    "            self.intermediate_probabilities.append(probabilities)\n",
    "            self.intermediate_graphs.append(g)\n",
    "\n",
    "    def predict(self):\n",
    "        stride = self.prediction_stride\n",
    "        image = self.image\n",
    "        image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "        all_tiles = image_tensor.unfold(0, self.tile_size[0], stride).unfold(1, self.tile_size[1], stride).reshape(-1, 1, self.tile_size[0], self.tile_size[1]).to(device)\n",
    "\n",
    "        all_tiles_ds = TileDS(all_tiles)\n",
    "\n",
    "        # set up dataloaders\n",
    "        loader = torch.utils.data.DataLoader(all_tiles_ds, batch_size=4096, shuffle=False)\n",
    "        n_batches = len(loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_tiles_predictions = torch.zeros((len(all_tiles_ds))).to(device)\n",
    "            for batch_i, batch in tqdm(enumerate(loader), total=n_batches):\n",
    "                batch_predictions = self.net(batch)\n",
    "                all_tiles_predictions[batch_i*loader.batch_size:(batch_i+1)*loader.batch_size] = batch_predictions.squeeze(1)\n",
    "\n",
    "        predictions = all_tiles_predictions.reshape(((self.size[0] - self.tile_size[0]) // stride) + 1, ((self.size[1] - self.tile_size[1]) // stride) + 1)\n",
    "        pixelwise_probabilities = torch.nn.functional.interpolate(predictions.unsqueeze(0).unsqueeze(0), size=image.shape, mode='bilinear', align_corners=True)\n",
    "        pixelwise_probabilities -= pixelwise_probabilities.min()\n",
    "        pixelwise_probabilities /= pixelwise_probabilities.max()\n",
    "        pixelwise_probabilities *= 255\n",
    "        pixelwise_probabilities = pixelwise_probabilities.squeeze(0).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "        grayscale = False\n",
    "        if 3 not in image.shape:\n",
    "            grayscale = True\n",
    "            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "        segments = slic(image, n_segments=100, sigma=3)\n",
    "        segmentation = color.label2rgb(segments, pixelwise_probabilities, kind='avg', bg_label=0)\n",
    "        segmentation = segmentation > auto_threshold(segmentation)\n",
    "        if grayscale:\n",
    "            segmentation = segmentation[:, :, 0]\n",
    "        return segmentation\n",
    "    \n",
    "def generate_training_report(segmentor):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
    "    axs[0].set_title('Image')\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(segmentor.image, cmap='gray')\n",
    "    axs[1].set_title('Network Loss')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    axs[1].plot(segmentor.losses)\n",
    "    axs[2].set_title('Final Network Probabilities')\n",
    "    axs[2].axis('off')\n",
    "    axs[2].imshow(segmentor.intermediate_probabilities[-1].reshape(segmentor.d, segmentor.d))\n",
    "    axs[3].set_title('Final Graph Partition')\n",
    "    axs[3].axis('off')\n",
    "    axs[3].imshow(segmentor.intermediate_partitions[-1].reshape(segmentor.d, segmentor.d))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_complex_image(size=(224, 224), noise=0, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    mask_paths = glob.glob(\"blobs/*.png\")\n",
    "    texture_paths = glob.glob(\"textures/*.tiff\")\n",
    "    mask_path = np.random.choice(mask_paths)\n",
    "    texture1_path, texture2_path = np.random.choice(texture_paths, size=2)\n",
    "    mask = np.array(Image.open(mask_path).resize(size, resample=Image.NEAREST))\n",
    "    texture1 = np.array(Image.open(texture1_path).resize(size, resample=Image.NEAREST))\n",
    "    texture2 = np.array(Image.open(texture2_path).resize(size, resample=Image.NEAREST))\n",
    "    image = np.where(mask > 0, texture1, texture2) / 255\n",
    "    labels = mask > 0\n",
    "    if noise > 0:\n",
    "        image = add_noise(image, amount=noise, seed=seed)\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-V] command ...\n",
      "\n",
      "conda is a tool for managing and deploying applications, environments and packages.\n",
      "\n",
      "Options:\n",
      "\n",
      "positional arguments:\n",
      "  command\n",
      "    clean        Remove unused packages and caches.\n",
      "    compare      Compare packages between conda environments.\n",
      "    config       Modify configuration values in .condarc. This is modeled\n",
      "                 after the git config command. Writes to the user .condarc\n",
      "                 file (/Users/isaac/.condarc) by default.\n",
      "    create       Create a new conda environment from a list of specified\n",
      "                 packages.\n",
      "    help         Displays a list of available conda commands and their help\n",
      "                 strings.\n",
      "    info         Display information about current conda install.\n",
      "    init         Initialize conda for shell interaction. [Experimental]\n",
      "    install      Installs a list of packages into a specified conda\n",
      "                 environment.\n",
      "    list         List linked packages in a conda environment.\n",
      "    package      Low-level conda package utility. (EXPERIMENTAL)\n",
      "    remove       Remove a list of packages from a specified conda environment.\n",
      "    uninstall    Alias for conda remove.\n",
      "    run          Run an executable in a conda environment. [Experimental]\n",
      "    search       Search for packages and display associated information. The\n",
      "                 input is a MatchSpec, a query language for conda packages.\n",
      "                 See examples below.\n",
      "    update       Updates conda packages to the latest compatible version.\n",
      "    upgrade      Alias for conda update.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     Show this help message and exit.\n",
      "  -V, --version  Show the conda version number and exit.\n",
      "\n",
      "conda commands available from other packages:\n",
      "  env\n"
     ]
    }
   ],
   "source": [
    "!conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcompile(generate_complex_image)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "torch.compile(generate_complex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 65ne750t\n",
      "Sweep URL: https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'Avg. F1 Score',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'd': {\n",
    "            'values': [8, 16, 32, 64]\n",
    "        },\n",
    "        'n_filters': {\n",
    "            'values': [16, 32, 64, 128]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        },\n",
    "        'lambda_': {\n",
    "            'values': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "        },\n",
    "        'iterations': {\n",
    "            'values': [100, 200, 300, 400, 500]\n",
    "        },\n",
    "        'subset_size': {\n",
    "            'values': [0.1, 0.3, 0.5, 0.7]\n",
    "        },\n",
    "        'prediction_stride': {\n",
    "            'value': 4\n",
    "        },\n",
    "        'image_size': {\n",
    "            'value': (512,512)\n",
    "        },\n",
    "        'noise': {\n",
    "            'value': 0\n",
    "        },\n",
    "        'seed': {\n",
    "            'value': 0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "representative_test_images = [\n",
    "    \"gt_2.png_1.1.01.tiff_1.1.04.tiff\", # easy\n",
    "    \"gt_2.png_1.1.01.tiff_1.1.12.tiff\", # easy\n",
    "    \"gt_2.png_1.1.02.tiff_1.1.05.tiff\", # medium\n",
    "    \"gt_2.png_1.1.02.tiff_1.1.13.tiff\", # medium\n",
    "    \"gt_2.png_1.1.03.tiff_1.1.02.tiff\", # hard\n",
    "    \"gt_2.png_1.1.03.tiff_1.1.04.tiff\"  # hard\n",
    "]\n",
    "\n",
    "#  size=(512,512),  d=16,        fore_back_ratio=0.2,\n",
    "# noise=1,         seed=0,      iterations=200,\n",
    "# lr=0.001,        lambda_=0.2, n_filters=32,\n",
    "# subset_size=0.5, dropout=0.2,  prediction_stride=4\n",
    "\n",
    "def run_experiment(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        f1_scores = np.zeros(len(representative_test_images))\n",
    "        for image_index, test_image_name in enumerate(representative_test_images):\n",
    "            image = np.array(Image.open(f'test_images/{test_image_name}_image.png').resize(config.image_size, resample=Image.NEAREST)) / 255\n",
    "            pixelwise_labels = np.array(Image.open(f'test_images/{test_image_name}_labels.png').resize(config.image_size, resample=Image.NEAREST)) > 0\n",
    "            segmentor = GraphicallyGuidedEMSegmentor(d=config.d, n_filters=config.n_filters, dropout=config.dropout, lambda_=config.lambda_, size=config.image_size, lr=config.lr, iterations=config.iterations, subset_size=config.subset_size, prediction_stride=config.prediction_stride, seed=config.seed)\n",
    "            segmentor.fit(image)\n",
    "            segmentation = segmentor.predict()\n",
    "            accuracy, report, conf_matrix = evaluate(pixelwise_labels, segmentation, plot=False)\n",
    "            f1_scores[image_index] = report[\"weighted avg\"][\"f1-score\"]\n",
    "        wandb.log({\"Avg. F1 Score\": f1_scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: 🚀 View run usual-sweep-2 at: https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lazrda4k\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230225_160752-lazrda4k/logs\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.85s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6id50if with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.1\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_160924-a6id50if</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/a6id50if' target=\"_blank\">sweepy-sweep-1</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/a6id50if' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/a6id50if</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.09s/it]\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.83s/it]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.70211</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweepy-sweep-1</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/a6id50if' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/a6id50if</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_160924-a6id50if/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run a6id50if errored: Error('You must call wandb.init() before wandb.log()')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3owio062 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_161214-3owio062</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/3owio062' target=\"_blank\">radiant-sweep-2</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/3owio062' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/3owio062</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.27it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.6346</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-2</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/3owio062' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/3owio062</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_161214-3owio062/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87ehy5pv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_161539-87ehy5pv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/87ehy5pv' target=\"_blank\">hardy-sweep-3</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/87ehy5pv' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/87ehy5pv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.36it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.37it/s]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.72313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-3</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/87ehy5pv' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/87ehy5pv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_161539-87ehy5pv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lb9ax38f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_161737-lb9ax38f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lb9ax38f' target=\"_blank\">helpful-sweep-4</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lb9ax38f' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lb9ax38f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.45it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.65773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-4</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lb9ax38f' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/lb9ax38f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_161737-lb9ax38f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hshdzkjn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_161843-hshdzkjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/hshdzkjn' target=\"_blank\">cool-sweep-5</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/65ne750t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/hshdzkjn' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/hshdzkjn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.91s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.91s/it]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.20s/it]\n",
      "100%|██████████| 4/4 [00:13<00:00,  3.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.78698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-sweep-5</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/hshdzkjn' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/hshdzkjn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_161843-hshdzkjn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x2b428b6d0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/backcall/backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 kwargs\u001b[39m.\u001b[39mpop(name)\n\u001b[1;32m    103\u001b[0m \u001b[39m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m             \u001b[39mreturn\u001b[39;00m callback(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:404\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39minterface \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mpausing backend\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend\u001b[39m.\u001b[39;49minterface\u001b[39m.\u001b[39;49mpublish_pause()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:666\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpublish_pause\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     pause \u001b[39m=\u001b[39m pb\u001b[39m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 666\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_publish_pause(pause)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_publish_pause\u001b[39m(\u001b[39mself\u001b[39m, pause: pb\u001b[39m.\u001b[39mPauseRequest) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     rec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(pause\u001b[39m=\u001b[39mpause)\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_publish(rec)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_publish\u001b[39m(\u001b[39mself\u001b[39m, record: \u001b[39m\"\u001b[39m\u001b[39mpb.Record\u001b[39m\u001b[39m\"\u001b[39m, local: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock_client\u001b[39m.\u001b[39;49msend_record_publish(record)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[39m=\u001b[39m spb\u001b[39m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[39m.\u001b[39mrecord_publish\u001b[39m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_server_request(server_req)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_server_request\u001b[39m(\u001b[39mself\u001b[39m, msg: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(msg)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39mpack(\u001b[39m\"\u001b[39m\u001b[39m<BI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mord\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sendall_with_error_handle(header \u001b[39m+\u001b[39;49m data)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[39m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m sent \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# set environment variable\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"experiment.ipynb\"\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Graphically Guided Neural EM for Unsupervised Image Segmentation\")\n",
    "wandb.agent(sweep_id, run_experiment, count=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d24a1087ab98538c556b121a84e46182f365585e86aa7ee7d846ee7e5fae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
