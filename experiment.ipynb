{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaac/miniforge3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33misaacwasserman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pprint\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.util as util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import igraph as ig\n",
    "from igraph import Graph\n",
    "import sklearn.metrics as metrics\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import skimage.filters\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage import data, segmentation, color\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext line_profiler\n",
    "from time import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def generate_square(size=(224, 224), fore_back_ratio=0.5, noise=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    square_width = int(np.sqrt(fore_back_ratio * size[0] * size[1]))\n",
    "    square_position_x = np.random.randint(0, size[0] - square_width)\n",
    "    square_position_y = np.random.randint(0, size[1] - square_width)\n",
    "    image = np.ones(size)\n",
    "    image[square_position_x:square_position_x+square_width, square_position_y:square_position_y+square_width] = 0\n",
    "    return image\n",
    "\n",
    "def add_noise(image, amount=0.5, seed=None):\n",
    "    image = util.random_noise(image, mode='gaussian', seed=seed, clip=False, var=amount)\n",
    "    image = image / np.max(image)\n",
    "    return image\n",
    "\n",
    "def generate_image(size=(224, 224), fore_back_ratio=0.5, noise=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    image = generate_square(size, fore_back_ratio, noise, seed)\n",
    "    pixelwise_labels = image.copy()\n",
    "    image = add_noise(image, amount=noise, seed=seed)\n",
    "    return image, pixelwise_labels\n",
    "\n",
    "def tile(image, pixelwise_labels=None, method='grid', d=10):\n",
    "    if method == 'grid':\n",
    "        if image.shape[0] % d != 0 or image.shape[1] % d != 0:\n",
    "            raise ValueError('image shape must be divisible by d')\n",
    "        else:\n",
    "            tile_width = (image.shape[0] // d)\n",
    "            tile_height = (image.shape[1] // d)\n",
    "            image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "            if len(image_tensor.shape) < 3:\n",
    "                image_tensor = image_tensor.unsqueeze(2)\n",
    "            tiles = image_tensor.unfold(0, tile_width, tile_height).unfold(1, tile_width, tile_height)\n",
    "            tiles = tiles.permute(0, 1, 3, 4, 2)\n",
    "            tiles = tiles.reshape(tiles.shape[0] * tiles.shape[1], tile_width, tile_height, tiles.shape[4])\n",
    "\n",
    "            if pixelwise_labels is not None:\n",
    "                pixelwise_labels_tensor = torch.tensor(pixelwise_labels)\n",
    "                if len(pixelwise_labels_tensor.shape) < 3:\n",
    "                    image_tensor = image_tensor.unsqueeze(2)\n",
    "                pixelwise_labels_tiles = pixelwise_labels_tensor.unfold(0, tile_width, tile_height).unfold(1, tile_width, tile_height)\n",
    "                pixelwise_labels_tiles = pixelwise_labels_tiles.reshape(pixelwise_labels_tiles.shape[0] * pixelwise_labels_tiles.shape[1], tile_width * tile_height)\n",
    "                tilewise_labels = pixelwise_labels_tiles.mean(axis=1).round()\n",
    "                return tiles, tilewise_labels\n",
    "            else:\n",
    "                return tiles\n",
    "    else:\n",
    "        raise ValueError('method not implemented')\n",
    "    \n",
    "\n",
    "def arbitrary_labels(n, proportion=0.5, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.random.manual_seed(seed)\n",
    "    randoms = torch.rand(n)\n",
    "    labels = torch.zeros(n)\n",
    "    labels[randoms > proportion] = 1\n",
    "    return labels\n",
    "\n",
    "def generate_tiles(size=(224, 224), fore_back_ratio=0.5, noise=0.5, d=8, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    image, pixelwise_labels = generate_image(size, fore_back_ratio, noise, seed)\n",
    "    tiles, tilewise_labels = tile(image, pixelwise_labels, d=d)\n",
    "    return tiles, tilewise_labels, arbitrary_labels(tilewise_labels.shape[0], seed=seed)\n",
    "\n",
    "def visualize_tiles(tiles, tilewise_labels=None, show_labels=True):\n",
    "    d = int(np.sqrt(tiles.shape[0]))\n",
    "    fig, axs = plt.subplots(d,d, figsize=(d//2,d//2))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            axs[i, j].imshow(tiles[i * d + j], cmap='gray', vmin=0, vmax=1)\n",
    "            if show_labels and tilewise_labels is not None:\n",
    "                axs[i, j].text(2, 2, f'{tilewise_labels[i * d + j]:.2f}', color='white', fontsize=6, bbox=dict(fill=True, facecolor='purple', linewidth=0), verticalalignment='top', horizontalalignment='left')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def graph_cut(d, probabilities, lambda_):\n",
    "    g = Graph.Lattice(dim=[d, d], circular=False)\n",
    "    g.add_vertices(2)\n",
    "    weights = np.zeros(g.ecount() + (2*d*d))\n",
    "    s = d*d\n",
    "    t = s + 1\n",
    "    st_edges = np.array([(i, s) for i in range(d*d)] + [(i, t) for i in range(d*d)])\n",
    "    g.add_edges(st_edges)\n",
    "    weights[:-2*d*d] = lambda_\n",
    "    scaled_probabilities = (probabilities - probabilities.min()) / (probabilities.max() - probabilities.min())\n",
    "    weights[-2*d*d:-1*d*d] = scaled_probabilities\n",
    "    weights[-1*d*d:] = 1 - scaled_probabilities\n",
    "    g.es['weight'] = weights\n",
    "\n",
    "    colors = np.concatenate((np.zeros(d*d), np.array([1,2])))\n",
    "    g.vs[\"color\"] = [\"gray\" if c == 0 else (\"black\" if c == 1 else \"white\") for c in colors]\n",
    "\n",
    "    # assignments = np.array(g.maxflow(s, t, \"weight\").membership[:-2])\n",
    "\n",
    "    mc = g.st_mincut(s, t, \"weight\")\n",
    "    bg = mc.partition[0]\n",
    "    bg.remove(s)\n",
    "    assignments = np.zeros(d*d)\n",
    "    assignments[bg] = 1\n",
    "    return assignments, g\n",
    "\n",
    "def visualize_graph(g, d, labels=None):\n",
    "    if labels is None:\n",
    "        colors = np.concatenate((np.zeros(d*d), np.array([2,3])))\n",
    "        g.vs[\"color\"] = [\"gray\" if c == 0 else (\"black\" if c == 2 else \"white\") for c in colors]\n",
    "    else:\n",
    "        colors = np.concatenate((labels.astype(int), np.array([1,0])))\n",
    "        g.vs[\"color\"] = [\"black\" if c == 0 else \"white\" for c in colors]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    layout = np.zeros((d*d + 2, 2))\n",
    "    for i in range(d*d + 2):\n",
    "        if i < d*d:\n",
    "            layout[i, 0] = (i % d)\n",
    "            layout[i, 1] = -1 * (i // d)\n",
    "        elif i == d*d:\n",
    "            layout[i, 1] = 2\n",
    "            layout[i, 0] = (d - 1) / 2\n",
    "        elif i == d*d + 1:\n",
    "            layout[i, 1] = -1 * (d + 1)\n",
    "            layout[i, 0] = (d - 1) / 2\n",
    "\n",
    "    n_edges = g.ecount()\n",
    "    n_lattice_edges = n_edges - 2*d*d\n",
    "            \n",
    "    ig.plot(g, target=ax, edge_width=g.es[\"weight\"], layout=layout)\n",
    "    plt.show()\n",
    "\n",
    "def auto_threshold(probabilities):\n",
    "    t = skimage.filters.threshold_otsu(probabilities)\n",
    "    return t\n",
    "\n",
    "def evaluate(pixelwise_probabilities, pixelwise_labels, allow_inverse=True, plot=True):\n",
    "    pixelwise_predictions = pixelwise_probabilities\n",
    "    pixelwise_predictions = pixelwise_predictions.astype(int).reshape(-1)\n",
    "    pixelwise_labels = pixelwise_labels.astype(int).reshape(-1)\n",
    "    accuracy = accuracy_score(pixelwise_labels, pixelwise_predictions)\n",
    "    if allow_inverse and accuracy < 0.5:\n",
    "        pixelwise_predictions = 1 - pixelwise_predictions\n",
    "        accuracy = accuracy_score(pixelwise_labels, pixelwise_predictions)\n",
    "    report = classification_report(pixelwise_labels, pixelwise_predictions, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(pixelwise_labels, pixelwise_predictions)\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "        sns.heatmap(conf_matrix, ax=axs[0], annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "        axs[0].set_title('Confusion Matrix')\n",
    "        sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, ax=axs[1], annot=True)\n",
    "        axs[1].set_title('Classification Report')\n",
    "        illustration = pixelwise_labels.reshape(pixelwise_probabilities.shape[0], pixelwise_probabilities.shape[1]) != pixelwise_predictions.reshape(pixelwise_probabilities.shape[0], pixelwise_probabilities.shape[1])\n",
    "        axs[2].imshow(illustration)\n",
    "        axs[2].set_title('Incorrect Predictions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        return accuracy, report, conf_matrix\n",
    "\n",
    "class TileDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, image_size=(32,32), n_filters=16, n_channels=1, dropout=0.2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, n_filters, 3, padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(n_filters)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters, 3, padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(n_filters)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.conv3 = nn.Conv2d(n_filters, 1, 3, padding=1)\n",
    "        self.BN3 = nn.BatchNorm2d(1)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(image_size[0] * image_size[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.BN1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.BN2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.BN3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphicallyGuidedEMSegmentor:\n",
    "    def __init__(self, d=16, n_filters=16, dropout=0.2, lambda_=0.3, size=(512, 512), lr=0.001, iterations=100, subset_size=0.5, prediction_stride=1, seed=0):\n",
    "        self.d = d\n",
    "        self.n_filters = n_filters\n",
    "        self.dropout = dropout\n",
    "        self.lambda_ = lambda_\n",
    "        self.size = size\n",
    "        self.tile_size = (size[0] // d, size[1] // d)\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.subset_size = subset_size\n",
    "        self.prediction_stride = prediction_stride\n",
    "        self.seed = seed\n",
    "        self.net = None\n",
    "        self.losses = []\n",
    "        self.intermediate_partitions = []\n",
    "        self.intermediate_probabilities = []\n",
    "        self.intermediate_graphs = []\n",
    "\n",
    "    def fit(self, image):\n",
    "        self.losses = []\n",
    "        self.intermediate_partitions = []\n",
    "        self.intermediate_probabilities = []\n",
    "        self.intermediate_graphs = []\n",
    "        self.image = image\n",
    "        \n",
    "        X = tile(image, d=self.d).type(torch.float32).to(device).permute(0, 3, 1, 2)\n",
    "        y_initial = arbitrary_labels(self.d**2, seed=self.seed).type(torch.float32).to(device).unsqueeze(1)\n",
    "        torch.manual_seed(self.seed)\n",
    "        self.net = CNN(image_size=self.tile_size, n_filters=self.n_filters, n_channels=X.shape[1], dropout=self.dropout).to(device)\n",
    "        \n",
    "        # train CNN\n",
    "        y_intermediate = y_initial.clone().detach()\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "        itertimes = []\n",
    "        graphtimes = []\n",
    "        for iteration in range(self.iterations):\n",
    "            start = time()\n",
    "            # extract subset of data\n",
    "            shuffled_idx = torch.randperm(X.shape[0])\n",
    "            X_shuffled = X[shuffled_idx]\n",
    "            y_intermediate_shuffled = y_intermediate[shuffled_idx]\n",
    "            X_subset = X_shuffled[:int(self.subset_size * X.shape[0])]\n",
    "            y_intermediate_subset = y_intermediate_shuffled[:int(self.subset_size * X.shape[0])]\n",
    "\n",
    "            inputs = X_subset\n",
    "            labels = y_intermediate_subset\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update y_intermediate\n",
    "            probabilities = self.net(X).detach().squeeze(1).cpu().numpy()\n",
    "            graph_start = time()\n",
    "            partition, g = graph_cut(self.d, probabilities, self.lambda_)\n",
    "            graphtimes.append(time() - graph_start)\n",
    "            y_intermediate = torch.Tensor(partition).type(torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "            # save intermediate results\n",
    "            self.losses.append(loss.item() / X.shape[0])\n",
    "            self.intermediate_partitions.append(partition)\n",
    "            self.intermediate_probabilities.append(probabilities)\n",
    "            self.intermediate_graphs.append(g)\n",
    "            itertimes.append(time() - start)\n",
    "        print(\"Average training time per iteration:\", np.array(itertimes).mean())\n",
    "        print(\"Average graph cut time:\", np.array(graphtimes).mean())\n",
    "\n",
    "    def predict(self):\n",
    "        stride = self.prediction_stride\n",
    "        image = self.image\n",
    "        image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "        all_tiles = image_tensor.unfold(0, self.tile_size[0], stride).unfold(1, self.tile_size[1], stride).reshape(-1, 1, self.tile_size[0], self.tile_size[1]).to(device)\n",
    "\n",
    "        all_tiles_ds = TileDS(all_tiles)\n",
    "\n",
    "        # set up dataloaders\n",
    "        batch_size = 4096\n",
    "        if device == \"cuda\":\n",
    "            batch_size = 16384\n",
    "        loader = torch.utils.data.DataLoader(all_tiles_ds, batch_size=batch_size, shuffle=False)\n",
    "        n_batches = len(loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_tiles_predictions = torch.zeros((len(all_tiles_ds))).to(device)\n",
    "            for batch_i, batch in tqdm(enumerate(loader), total=n_batches):\n",
    "                batch_predictions = self.net(batch)\n",
    "                all_tiles_predictions[batch_i*loader.batch_size:(batch_i+1)*loader.batch_size] = batch_predictions.squeeze(1)\n",
    "\n",
    "        predictions = all_tiles_predictions.reshape(((self.size[0] - self.tile_size[0]) // stride) + 1, ((self.size[1] - self.tile_size[1]) // stride) + 1)\n",
    "        pixelwise_probabilities = torch.nn.functional.interpolate(predictions.unsqueeze(0).unsqueeze(0), size=image.shape, mode='bilinear', align_corners=True)\n",
    "        pixelwise_probabilities -= pixelwise_probabilities.min()\n",
    "        pixelwise_probabilities /= pixelwise_probabilities.max()\n",
    "        pixelwise_probabilities *= 255\n",
    "        pixelwise_probabilities = pixelwise_probabilities.squeeze(0).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "        grayscale = False\n",
    "        if 3 not in image.shape:\n",
    "            grayscale = True\n",
    "            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "        segments = slic(image, n_segments=100, sigma=3)\n",
    "        segmentation = color.label2rgb(segments, pixelwise_probabilities, kind='avg', bg_label=0)\n",
    "        segmentation = segmentation > auto_threshold(segmentation)\n",
    "        if grayscale:\n",
    "            segmentation = segmentation[:, :, 0]\n",
    "        return segmentation\n",
    "    \n",
    "def generate_training_report(segmentor):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
    "    axs[0].set_title('Image')\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(segmentor.image, cmap='gray')\n",
    "    axs[1].set_title('Network Loss')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    axs[1].plot(segmentor.losses)\n",
    "    axs[2].set_title('Final Network Probabilities')\n",
    "    axs[2].axis('off')\n",
    "    axs[2].imshow(segmentor.intermediate_probabilities[-1].reshape(segmentor.d, segmentor.d))\n",
    "    axs[3].set_title('Final Graph Partition')\n",
    "    axs[3].axis('off')\n",
    "    axs[3].imshow(segmentor.intermediate_partitions[-1].reshape(segmentor.d, segmentor.d))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_complex_image(size=(224, 224), noise=0, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    mask_paths = glob.glob(\"blobs/*.png\")\n",
    "    texture_paths = glob.glob(\"textures/*.tiff\")\n",
    "    mask_path = np.random.choice(mask_paths)\n",
    "    texture1_path, texture2_path = np.random.choice(texture_paths, size=2)\n",
    "    mask = np.array(Image.open(mask_path).resize(size, resample=Image.NEAREST))\n",
    "    texture1 = np.array(Image.open(texture1_path).resize(size, resample=Image.NEAREST))\n",
    "    texture2 = np.array(Image.open(texture2_path).resize(size, resample=Image.NEAREST))\n",
    "    image = np.where(mask > 0, texture1, texture2) / 255\n",
    "    labels = mask > 0\n",
    "    if noise > 0:\n",
    "        image = add_noise(image, amount=noise, seed=seed)\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'Avg. F1 Score',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'd': {\n",
    "            'values': [8, 16, 32, 64]\n",
    "        },\n",
    "        'n_filters': {\n",
    "            'values': [16, 32, 64, 128]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        },\n",
    "        'lambda_': {\n",
    "            'values': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "        },\n",
    "        'iterations': {\n",
    "            'values': [100, 200, 300, 400, 500]\n",
    "        },\n",
    "        'subset_size': {\n",
    "            'values': [0.1, 0.3, 0.5, 0.7]\n",
    "        },\n",
    "        'prediction_stride': {\n",
    "            'value': 4\n",
    "        },\n",
    "        'image_size': {\n",
    "            'value': (512,512)\n",
    "        },\n",
    "        'noise': {\n",
    "            'value': 0\n",
    "        },\n",
    "        'seed': {\n",
    "            'value': 0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "representative_test_images = [\n",
    "    \"gt_2.png_1.1.01.tiff_1.1.04.tiff\", # easy\n",
    "    \"gt_2.png_1.1.01.tiff_1.1.12.tiff\", # easy\n",
    "    \"gt_2.png_1.1.02.tiff_1.1.05.tiff\", # medium\n",
    "    \"gt_2.png_1.1.02.tiff_1.1.13.tiff\", # medium\n",
    "    \"gt_2.png_1.1.03.tiff_1.1.02.tiff\", # hard\n",
    "    \"gt_2.png_1.1.03.tiff_1.1.04.tiff\"  # hard\n",
    "]\n",
    "\n",
    "#  size=(512,512),  d=16,        fore_back_ratio=0.2,\n",
    "# noise=1,         seed=0,      iterations=200,\n",
    "# lr=0.001,        lambda_=0.2, n_filters=32,\n",
    "# subset_size=0.5, dropout=0.2,  prediction_stride=4\n",
    "\n",
    "def run_experiment(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        f1_scores = np.zeros(len(representative_test_images))\n",
    "        for image_index, test_image_name in enumerate(representative_test_images):\n",
    "            image = np.array(Image.open(f'test_images/{test_image_name}_image.png').resize(config.image_size, resample=Image.NEAREST)) / 255\n",
    "            pixelwise_labels = np.array(Image.open(f'test_images/{test_image_name}_labels.png').resize(config.image_size, resample=Image.NEAREST)) > 0\n",
    "            segmentor = GraphicallyGuidedEMSegmentor(d=config.d, n_filters=config.n_filters, dropout=config.dropout, lambda_=config.lambda_, size=config.image_size, lr=config.lr, iterations=config.iterations, subset_size=config.subset_size, prediction_stride=config.prediction_stride, seed=config.seed)\n",
    "            segmentor.fit(image)\n",
    "            segmentation = segmentor.predict()\n",
    "            accuracy, report, conf_matrix = evaluate(pixelwise_labels, segmentation, plot=False)\n",
    "            f1_scores[image_index] = report[\"weighted avg\"][\"f1-score\"]\n",
    "        wandb.log({\"Avg. F1 Score\": f1_scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: meurato8\n",
      "Sweep URL: https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/meurato8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ks2licv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_size: [512, 512]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprediction_stride: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubset_size: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/isaac/Desktop/Thesis/Second Semester/Implementation/wandb/run-20230225_213756-4ks2licv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/4ks2licv' target=\"_blank\">genial-sweep-1</a></strong> to <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/meurato8' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/meurato8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/meurato8' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/sweeps/meurato8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/4ks2licv' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/4ks2licv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.15772800048192342\n",
      "Average graph cut time: 0.00127090056737264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.11540893077850342\n",
      "Average graph cut time: 0.0007475113868713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.11882026592890421\n",
      "Average graph cut time: 0.0010495448112487792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.1187296438217163\n",
      "Average graph cut time: 0.0010071523984273275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.11802171150843302\n",
      "Average graph cut time: 0.0010709047317504882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time per iteration: 0.11797998825709025\n",
      "Average graph cut time: 0.0010136818885803222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg. F1 Score</td><td>0.66466</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-1</strong> at: <a href='https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/4ks2licv' target=\"_blank\">https://wandb.ai/isaacwasserman/Graphically%20Guided%20Neural%20EM%20for%20Unsupervised%20Image%20Segmentation/runs/4ks2licv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_213756-4ks2licv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set environment variable\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"experiment.ipynb\"\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Graphically Guided Neural EM for Unsupervised Image Segmentation\")\n",
    "wandb.agent(sweep_id, function=run_experiment, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d24a1087ab98538c556b121a84e46182f365585e86aa7ee7d846ee7e5fae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
